name: Benchmarks
on:
  push:
    branches:
      - main
      - custom-dashboarding
  workflow_dispatch:

concurrency:
  # Fairly strict concurrency rule to avoid stepping on benchmark db.
  # Could eventually replace with a real db in coiled, RDS, or litestream
  group: benchmarks
  cancel-in-progress: false

defaults:
  # Required shell entrypoint to have properly activated conda environments
  run:
    shell: bash -l {0}

jobs:
  benchmarks:
    name: Benchmarks - ${{ matrix.os }}, Python ${{ matrix.python-version }}, Runtime ${{ matrix.runtime-version }}
    runs-on: ${{ matrix.os }}
    timeout-minutes: 120
    strategy:
      fail-fast: false
      matrix:
        os: ["ubuntu-latest"]
        python-version: ["3.8", "3.9", "3.10"]
        runtime-version: ["0.0.4"]

    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up environment
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          use-mamba: true
          python-version: ${{ matrix.python-version }}
          environment-file: ci/environment.yml

      - name: Install coiled-runtime
        env:
          COILED_RUNTIME_VERSION: ${{ matrix.runtime-version }}
        run: source ci/scripts/install_coiled_runtime.sh

      - name: Run benchmarks
        id: benchmark_tests
        env:
          DASK_COILED__TOKEN: ${{ secrets.COILED_BENCHMARK_BOT_TOKEN }}
          AWS_ACCESS_KEY_ID: ${{ secrets.RUNTIME_CI_BOT_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RUNTIME_CI_BOT_AWS_SECRET_ACCESS_KEY }}
          COILED_RUNTIME_VERSION: ${{ matrix.runtime-version }}
          DB_NAME: benchmark-${{ matrix.os }}-${{ matrix.runtime-version }}-py${{ matrix.python-version }}.db
        run: |
          bash ci/scripts/run_tests.sh tests/benchmarks/test_coiled.py::test_sample_memory --benchmark

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: benchmark-${{ matrix.os }}-${{ matrix.runtime-version }}-py${{ matrix.python-version }}
          path: benchmark-${{ matrix.os }}-${{ matrix.runtime-version }}-py${{ matrix.python-version }}.db
  process-results:
    needs: benchmarks
    name: Combine separate benchmark results
    if: always()
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - uses: actions/setup-python@v4

      - name: Install dependencies
        run: pip install alembic

      - uses: actions/download-artifact@v3
        with:
          path: benchmarks

      - name: Combine benchmarks
        run: |
          ls -lhR benchmarks
          bash ci/scripts/combine-dbs.sh

      - name: Upload benchmark results
        uses: actions/upload-artifact@v3
        with:
          name: benchmark.db
          path: benchmark.db

  static-site:
    if: false
    needs: benchmarks
    name: Build static dashboards
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up environment
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniforge-variant: Mambaforge
          use-mamba: true
          python-version: "3.9"
          environment-file: ci/environment-dashboard.yml

      - name: Generate dashboards
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.RUNTIME_CI_BOT_AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.RUNTIME_CI_BOT_AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: us-east-2  # this is needed for boto for some reason
        run: |
          aws s3 sync --include="benchmark*.db" s3://coiled-runtime-ci/benchmarks/ benchmarks/
          for FILE in benchmarks/*.db
          do
            python dashboard.py $FILE
          done

          mkdir static
          mv benchmarks/*.html static/

      - name: Deploy ðŸš€
        uses: JamesIves/github-pages-deploy-action@4.1.7
        with:
          branch: gh-pages
          folder: static
